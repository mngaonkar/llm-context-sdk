{
            "config_type": "llm_provider",
            "provider_name": "ollama",
            "model": "llava",
            "base_url": "http://10.0.0.147:11434",
            "temperature": 0.6,
            "template": "{context} {history} {question}",
            "input_variables": [
                "history",
                "context",
                "question"
            ]
}
