{"_default": {"1": {"config_type": "llm_provider", "provider_name": "llama_cpp", "model": "llava", "base_url": "http://localhost:11434", "temperature": 0.6}, "2": {"config_type": "llm_provider", "provider_name": "ollama", "model": "llava", "base_url": "http://localhost:11434", "temperature": 0.6}, "3": {"config_type": "llm_provider", "provider_name": "openai", "model": "gpt-3.5", "base_url": "http://localhost:11434", "temperature": 0.6}}}